<!DOCTYPE HTML>
<!--
	Forty by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Reflective Activity 1: Ethics in Computing in the age of Generative AI</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="../assets/css/main.css" />
		<noscript><link rel="stylesheet" href="../assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">


		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<a href="../index.html" class="logo"><span>MSc Artificial Intelligence - University of Essex</span></a>
						<nav>
							<a href="#menu">Menu</a>
						</nav>
					</header>

				<!-- Menu -->
					<nav id="menu">
						<ul class="links">
							<li><a href="../index.html">Portfolio Home</a></li>
							<li><a href="../research_methods.html">Module: Research Methods and Professional Practice</a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main" class="alt">

						<!-- One -->
							<section id="one">
								<div class="inner">
									<header class="major">
										<h1>Reflective Activity 1: Ethics in Computing in the age of Generative AI</h1>
									</header>

									<!-- Content -->
										<h2> </h2>
										<h3 id="content"> 
										</h3>
										
										<p> There is indeed a need for a different set of rules to tackle the giant that generative AI has become. Perhaps a hybrid approach, as the article (Deckard, 2023) suggests, that brings “a combination of technical expertise, interdisciplinary knowledge, strong communication skills, and a commitment to social responsibility” would help to keep this boon a boon.
										</p>		
										<p>	To sway from the computing industry for a brief moment, we can see how various sets of regulations/guidances impact any industry just the same. Medical device (MD) manufacturers working on new SaMDs (Software as a Medical Device) incorporating AI, are craving harmony in regulations. US FDA, in harmonization with UK MHRA (Medicines and Healthcare Products Regulatory Agency) and Health Canada, has created the concept of partially static-dynamic PCCPs (Predetermined Change Control Plans) for MD submissions and approvals in the respective countries. However, this is not something that all other major regulatory bodies (such as Australia’s Therapeutic Goods Administration or TGA) plan to adopt. This will create additional workload on the manufacturers (and regulators alike) to have to comply with different regulations for different countries, amplifying the already heavy workload that the dynamic nature of generative AI brings.
										</p>	
										<p>In reading the article (Corrêa, 2023), it is clear that private institutions such as IBM and Microsoft are stepping up with their own set of published documentation to have a stake in the game before the rules of the game are properly defined. Moreover, a discrepancy is already in the works with US and Europe taking the lead for producing documentation (being the leading voice) for AI governance. This creates additional governance-gap, so to speak, between the above world regions and underrepresented countries.
										</p>
										<p>Let’s look at top themes that stand out in documents centering Principled AI, and how various countries deal with this generative AI revolution:
										<ul>
										<li>Starting with a subset of ‘Privacy’, it can be seen how India and China agree that ‘consent’ of personal data (in AI context) provided initially or unknowingly may not be plenty, and any unconsented / excess data obtained should be further regulated or be made aware of on a mass scale (Fjeld, 2020). </li>	
										<li>‘Accountability’ as a theme will be discussed in the final suggestion / suitable course of action for this context.</li>
										<li>‘Safety and Security’ pertains to the reliability of AI as a system to conduct actions that do not harm its surroundings. It can be seen how the German AI strategy proposes relying on security standards for critical IT infrastructure, with European High Level Expert Group guidelines countering with fall-back option being a better fail-safe approach. This also hands some of the power back to human intervention, which can contribute to the feeling of safety in collaborating with this technology (Fjeld, 2020).</li>
										<li>‘Transparency and Explainability’ is another great theme that helps explain the thought process of industries and governments on this subject, and overall. A subset, ‘Transparency’, speaks to the design and/or implementation of an AI system to help with the operational oversight. The Toronto Declaration heavies on refraining the use of AI systems should the situation be within the high-risk bucket (Fjeld, 2020).</li>
										<li>‘Fairness and Non-discrimination’ is as important to AI systems in the human arena, as water is to a fish. Under the subset ‘Representative and High Quality Data’, The Montreal Declaration and the European Charter on AI in judicial systems mutually agree on the need for high quality and representative data, even though they identify that gold standard in data, if used for deterministic analysis, could be more harmful than useful (Fjeld, 2020).</li>
										<li>‘Human Control of Technology’ has a very interesting and self-explanatory subset, called the ‘Ability to Opt out of Automated Decision’. The following documents cover this principle, and show alignment in thought process between the respective countries on this principle subset: AI in the UK, the European High Level Expert Group guidelines, and the Smart Dubai AI principles. There is slight disagreement in the extent to which this principle should be aligned, however.</li>
										<li>‘Professional Responsibility’, in sync with the ‘Accountability’ theme, speaks to ‘Accuracy’ as a subset, to provide accurate information - whether that is e.g. classification information or prediction information. An aligned goal is to prevent AI’s use in spreading or creating false information. This is something that both Google, being an industry representative, and the Montreal Declaration agree on (Fjeld, 2020).</li>
										<li>‘Promotion of Human Values’ as a theme promotes commonality between two countries’ leading principles on the subject. The Chinese AI Governance Principles read the principle as something that promotes human civilization’s progress. To this, the Montreal Declaration agrees, and quotes “permit the growth of the well-being of all sentient beings” by, inter alia, “help[ing] individuals improve their living conditions, their health, and their working conditions, … allow[ing] people to exercise their mental and physical capacities [and]… not contribut[ing] to increasing stress, anxiety, or a sense of being harassed by one’s digital environment” (Fjeld, 2020).</li>
										</ul>
										<p>Having discussed all the above themes, a lack of consensus in principled AI can be seen. A suitable course of action for the computing industry would be to have a centralized, internationally agreed upon set of regulations for academia, governments, and industry to use alike (ideally coming from the government / legally binding). It can be seen how The Toronto Declaration, the German AI strategy, and part of the industry (Microsoft being the representative here) all somewhat agree on the thought process of creating a monitoring body for better ‘Accountability’ (Fjeld, 2020). Naturally, there will be some variations on the local level as there should be (for better adaptation and for legal purposes), which will only help with the dynamic nature of this international set of standards. One single source (or one single team) could learn from many subsets. To add on to this suggestion - there needs to be a working relationship between the regulators and the academic/industry professionals who are on the ground level, working with the technology and facing the ethical/professional issues on a daily basis.
										</p>
										
										<hr>
											References:
											<hr>
											Fjeld, J. et al. (2020). Principled Artificial Intelligence: Mapping Consensus in Ethical and Rights-Based Approaches to Principles for AI. Berkman Klein Center Research Publication No. 2020-1. Available from: http://dx.doi.org.uniessexlib.idm.oclc.org/10.2139/ssrn.3518482 [Accessed 23 August 2024].
											<hr>
											Corrêa, N. K. et al. (2023). Worldwide AI ethics: A review of 200 guidelines and recommendations for AI governance. Cornell University. Available from: https://doi.org/10.1016/j.patter.2023.100857 [Accessed 23 August 2024].
											<hr>
											Deckard, R. (2023). What are ethics in AI? Available from: https://www.bcs.org/articles-opinion-and-research/what-are-ethics-in-ai/ [Accessed 23 August 2024].

										</p>									
			</div>

		<!-- Scripts -->
		<script src="../assets/js/jquery.min.js"></script>
		<script src="../assets/js/jquery.scrolly.min.js"></script>
		<script src="../assets/js/jquery.scrollex.min.js"></script>
		<script src="../assets/js/browser.min.js"></script>
		<script src="../assets/js/breakpoints.min.js"></script>
		<script src="../assets/js/util.js"></script>
		<script src="../assets/js/main.js"></script>

	</body>
</html>

